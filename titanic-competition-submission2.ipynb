{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ============================================\n# 🧊 Titanic 生存予測プロジェクト\n# Author: k-ohyeah\n# Date: 2025-10-07\n# Model: Logistic Regression + Feature Engineering\n# ============================================\n\n# 目的：\n# Titanicデータセットを用いて、生存者を予測する分類モデルを作成する。\n# データ理解 → 前処理 → 特徴量エンジニアリング → モデル構築 → チューニング → 評価 の流れで進める。\n\n# 手順概要：\n# 1. データの確認・可視化\n# 2. 前処理（欠損補完、カテゴリ処理など）\n# 3. 特徴量エンジニアリング（Title作成、FamilySizeなど）\n# 4. モデル構築（ロジスティック回帰）\n# 5. モデル比較とチューニング（GridSearchCV）\n# 6. 最終評価と提出データ作成","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-06T16:41:20.706446Z","iopub.execute_input":"2025-10-06T16:41:20.706762Z","iopub.status.idle":"2025-10-06T16:41:20.725029Z","shell.execute_reply.started":"2025-10-06T16:41:20.706739Z","shell.execute_reply":"2025-10-06T16:41:20.724011Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"#ライブラリ読み込み\nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns \n\n#データ読み込み\ntrain = pd.read_csv(\"/kaggle/input/titanic/train.csv\") \ntest= pd.read_csv(\"/kaggle/input/titanic/test.csv\")\n\nraw_test=test\n\nprint(\"trainデータ\")\nprint(train.head())\n\nprint(\"testデータ\")\nprint(test.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T16:41:23.202574Z","iopub.execute_input":"2025-10-06T16:41:23.202891Z","iopub.status.idle":"2025-10-06T16:41:23.228621Z","shell.execute_reply.started":"2025-10-06T16:41:23.202869Z","shell.execute_reply":"2025-10-06T16:41:23.227698Z"}},"outputs":[{"name":"stdout","text":"trainデータ\n   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  \ntestデータ\n   PassengerId  Pclass                                          Name     Sex  \\\n0          892       3                              Kelly, Mr. James    male   \n1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n2          894       2                     Myles, Mr. Thomas Francis    male   \n3          895       3                              Wirz, Mr. Albert    male   \n4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n\n    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n0  34.5      0      0   330911   7.8292   NaN        Q  \n1  47.0      1      0   363272   7.0000   NaN        S  \n2  62.0      0      0   240276   9.6875   NaN        Q  \n3  27.0      0      0   315154   8.6625   NaN        S  \n4  22.0      1      1  3101298  12.2875   NaN        S  \n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"#欠損値チェック\n\n\nprint(\"trainデータ件数:\", len(train)) \nprint() #改行\nprint(\"各列の欠損数:\")\nprint(train.isnull().sum())\n\nprint() #改行\n\nprint(\"testデータ件数:\", len(test)) \nprint() #改行\nprint(\"各列の欠損数:\")\nprint(test.isnull().sum())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T16:41:28.962037Z","iopub.execute_input":"2025-10-06T16:41:28.962782Z","iopub.status.idle":"2025-10-06T16:41:28.971175Z","shell.execute_reply.started":"2025-10-06T16:41:28.962750Z","shell.execute_reply":"2025-10-06T16:41:28.970293Z"}},"outputs":[{"name":"stdout","text":"trainデータ件数: 891\n\n各列の欠損数:\nPassengerId      0\nSurvived         0\nPclass           0\nName             0\nSex              0\nAge            177\nSibSp            0\nParch            0\nTicket           0\nFare             0\nCabin          687\nEmbarked         2\ndtype: int64\n\ntestデータ件数: 418\n\n各列の欠損数:\nPassengerId      0\nPclass           0\nName             0\nSex              0\nAge             86\nSibSp            0\nParch            0\nTicket           0\nFare             1\nCabin          327\nEmbarked         0\ndtype: int64\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"#追加前処理（Title追加、年齢欠損値補完方法の変更）\n\n# 名前からタイトルを抽出\ntrain['Title'] = train['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntest['Title'] = test['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n\n# 各タイトルの出現回数を確認\nprint(\"=== Title counts (Train) ===\")\nprint(train['Title'].value_counts())\nprint(\"\\n=== Title counts (Test) ===\")\nprint(test['Title'].value_counts())\n\n# タイトルごとの生存率を確認\ntrain.groupby('Title')['Survived'].mean().sort_values(ascending=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T16:41:32.536630Z","iopub.execute_input":"2025-10-06T16:41:32.536940Z","iopub.status.idle":"2025-10-06T16:41:32.553093Z","shell.execute_reply.started":"2025-10-06T16:41:32.536918Z","shell.execute_reply":"2025-10-06T16:41:32.552292Z"}},"outputs":[{"name":"stdout","text":"=== Title counts (Train) ===\nTitle\nMr          517\nMiss        182\nMrs         125\nMaster       40\nDr            7\nRev           6\nMlle          2\nMajor         2\nCol           2\nCountess      1\nCapt          1\nMs            1\nSir           1\nLady          1\nMme           1\nDon           1\nJonkheer      1\nName: count, dtype: int64\n\n=== Title counts (Test) ===\nTitle\nMr        240\nMiss       78\nMrs        72\nMaster     21\nCol         2\nRev         2\nMs          1\nDr          1\nDona        1\nName: count, dtype: int64\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"Title\nSir         1.000000\nCountess    1.000000\nMs          1.000000\nMme         1.000000\nLady        1.000000\nMlle        1.000000\nMrs         0.792000\nMiss        0.697802\nMaster      0.575000\nCol         0.500000\nMajor       0.500000\nDr          0.428571\nMr          0.156673\nJonkheer    0.000000\nDon         0.000000\nRev         0.000000\nCapt        0.000000\nName: Survived, dtype: float64"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"#追加前処理（Title追加、年齢欠損値補完方法の変更）\n\n# Name列からTitle（敬称）を抽出 \ntrain['Title'] = train['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntest['Title'] = test['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n\n# === タイトルのグルーピング ===\n# 主な4タイトルはそのまま使用（Mr, Miss, Mrs, Master）\n# それ以外を Rare にまとめる\n\nrare_titles = [\n    'Dr', 'Rev', 'Col', 'Major', 'Capt', 'Countess', \n    'Lady', 'Sir', 'Don', 'Jonkheer', 'Mme', 'Mlle', 'Ms', 'Dona'\n]\n\n# タイトル変換マップ\ntitle_map = {t: 'Rare' for t in rare_titles}\n# Miss / Mrs 系をまとめて調整（Mlle→Miss、Mme→MrsはRareより前に処理）\ntitle_map.update({'Mlle': 'Miss', 'Ms': 'Miss', 'Mme': 'Mrs'})\n\n# 変換を適用\ntrain['Title'] = train['Title'].replace(title_map)\ntest['Title'] = test['Title'].replace(title_map)\n\n# タイトルの分布確認\nprint(\"--- trainデータ ---\")\nprint(train['Title'].value_counts())\nprint(\"\\n--- testデータ ---\")\nprint(test['Title'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T16:41:38.256364Z","iopub.execute_input":"2025-10-06T16:41:38.256955Z","iopub.status.idle":"2025-10-06T16:41:38.272596Z","shell.execute_reply.started":"2025-10-06T16:41:38.256931Z","shell.execute_reply":"2025-10-06T16:41:38.271543Z"}},"outputs":[{"name":"stdout","text":"--- trainデータ ---\nTitle\nMr        517\nMiss      185\nMrs       126\nMaster     40\nRare       23\nName: count, dtype: int64\n\n--- testデータ ---\nTitle\nMr        240\nMiss       79\nMrs        72\nMaster     21\nRare        6\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"#追加前処理（Title追加、年齢欠損値補完方法の変更）\n\n# タイトルごとの年齢中央値を確認\nprint(train.groupby('Title')['Age'].median())\n\n# タイトルごとの年齢中央値で欠損を補完\nfor dataset in [train, test]:\n    dataset['Age'] = dataset['Age'].fillna(\n        dataset.groupby('Title')['Age'].transform('median')\n    )\n\n\n# 確認\nprint(train['Age'].isnull().sum(), test['Age'].isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T16:41:42.796070Z","iopub.execute_input":"2025-10-06T16:41:42.796351Z","iopub.status.idle":"2025-10-06T16:41:42.809138Z","shell.execute_reply.started":"2025-10-06T16:41:42.796333Z","shell.execute_reply":"2025-10-06T16:41:42.808235Z"}},"outputs":[{"name":"stdout","text":"Title\nMaster     3.5\nMiss      21.0\nMr        30.0\nMrs       35.0\nRare      48.5\nName: Age, dtype: float64\n0 0\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"#追加前処理（Title追加、年齢欠損値補完方法の変更）\n\n# One-Hotエンコーディング（ダミー変数化）\ntrain = pd.get_dummies(train, columns=['Title'], drop_first=True, dtype=int)\ntest = pd.get_dummies(test, columns=['Title'], drop_first=True, dtype=int)\n\nprint(\"trainデータ\")\nprint(train.head())\n\nprint(\"testデータ\")\nprint(test.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T16:41:45.895692Z","iopub.execute_input":"2025-10-06T16:41:45.896033Z","iopub.status.idle":"2025-10-06T16:41:45.916587Z","shell.execute_reply.started":"2025-10-06T16:41:45.896003Z","shell.execute_reply":"2025-10-06T16:41:45.915805Z"}},"outputs":[{"name":"stdout","text":"trainデータ\n   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  Title_Miss  Title_Mr  \\\n0      0         A/5 21171   7.2500   NaN        S           0         1   \n1      0          PC 17599  71.2833   C85        C           0         0   \n2      0  STON/O2. 3101282   7.9250   NaN        S           1         0   \n3      0            113803  53.1000  C123        S           0         0   \n4      0            373450   8.0500   NaN        S           0         1   \n\n   Title_Mrs  Title_Rare  \n0          0           0  \n1          1           0  \n2          0           0  \n3          1           0  \n4          0           0  \ntestデータ\n   PassengerId  Pclass                                          Name     Sex  \\\n0          892       3                              Kelly, Mr. James    male   \n1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n2          894       2                     Myles, Mr. Thomas Francis    male   \n3          895       3                              Wirz, Mr. Albert    male   \n4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n\n    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  Title_Miss  Title_Mr  \\\n0  34.5      0      0   330911   7.8292   NaN        Q           0         1   \n1  47.0      1      0   363272   7.0000   NaN        S           0         0   \n2  62.0      0      0   240276   9.6875   NaN        Q           0         1   \n3  27.0      0      0   315154   8.6625   NaN        S           0         1   \n4  22.0      1      1  3101298  12.2875   NaN        S           0         0   \n\n   Title_Mrs  Title_Rare  \n0          0           0  \n1          1           0  \n2          0           0  \n3          0           0  \n4          1           0  \n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"#train前処理\n\n#欠損値補完\n\n# Embarked の欠損を最頻値で補完\ntrain['Embarked'] = train['Embarked'].fillna(train['Embarked'].mode()[0])\n\n# Fare の欠損を中央値で補完\ntrain['Fare'] = train['Fare'].fillna(train['Fare'].median())\n\n# Cabin → 欠損が多すぎるので「有無フラグ」を作成\ntrain['Cabin_flag'] = train['Cabin'].notnull().astype(int) \n\n#特徴量追加\n\n# 家族人数 = 同乗の兄弟/配偶者 (SibSp) + 親/子 (Parch) + 自分1人\ntrain['FamilySize'] = train['SibSp'] + train['Parch'] + 1\n\ntrain['Age*Class'] = train['Age'] * train['Pclass']\n\ntrain['Fare_per_person'] = train['Fare'] / (train['FamilySize'])\n#Titanicデータセットの  は チケット単位の合計運賃 を表しています。\n\ntrain['IsAlone'] = (train['FamilySize'] == 1).astype(int)\n#train[\"FamilySize\"] == 1\n\n#不要列削除\n\ncols_to_drop = ['PassengerId', 'Name', 'Ticket', 'Cabin']  # Cabinはフラグ作成済みなので本体は削除\ntrain = train.drop(columns=cols_to_drop)\n\n#カテゴリ変数のエンコーディング\n\nfrom sklearn.preprocessing import LabelEncoder\n\n# Sexを0,1に変換\nle = LabelEncoder()\ntrain['Sex'] = le.fit_transform(train['Sex'])\n\n# EmbarkedをOne-Hot\ntrain = pd.get_dummies(train, columns=['Embarked'], drop_first=True, dtype=int)\n\n#補完後の検査\n\nprint(\"trainデータ件数:\", len(train)) #データの 行数（観測数）\nprint() #改行\n\nprint(\"各列の欠損数(補完後):\")\nprint(train.isnull().sum())\nprint() #改行\n\nprint(train.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T16:42:01.673886Z","iopub.execute_input":"2025-10-06T16:42:01.674260Z","iopub.status.idle":"2025-10-06T16:42:01.700480Z","shell.execute_reply.started":"2025-10-06T16:42:01.674235Z","shell.execute_reply":"2025-10-06T16:42:01.699712Z"}},"outputs":[{"name":"stdout","text":"trainデータ件数: 891\n\n各列の欠損数(補完後):\nSurvived           0\nPclass             0\nSex                0\nAge                0\nSibSp              0\nParch              0\nFare               0\nTitle_Miss         0\nTitle_Mr           0\nTitle_Mrs          0\nTitle_Rare         0\nCabin_flag         0\nFamilySize         0\nAge*Class          0\nFare_per_person    0\nIsAlone            0\nEmbarked_Q         0\nEmbarked_S         0\ndtype: int64\n\n   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Title_Miss  Title_Mr  \\\n0         0       3    1  22.0      1      0   7.2500           0         1   \n1         1       1    0  38.0      1      0  71.2833           0         0   \n2         1       3    0  26.0      0      0   7.9250           1         0   \n3         1       1    0  35.0      1      0  53.1000           0         0   \n4         0       3    1  35.0      0      0   8.0500           0         1   \n\n   Title_Mrs  Title_Rare  Cabin_flag  FamilySize  Age*Class  Fare_per_person  \\\n0          0           0           0           2       66.0          3.62500   \n1          1           0           1           2       38.0         35.64165   \n2          0           0           0           1       78.0          7.92500   \n3          1           0           1           2       35.0         26.55000   \n4          0           0           0           1      105.0          8.05000   \n\n   IsAlone  Embarked_Q  Embarked_S  \n0        0           0           1  \n1        0           0           0  \n2        1           0           1  \n3        0           0           1  \n4        1           0           1  \n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"#test前処理\n\n#欠損値補完\n\n# Embarked の欠損を最頻値で補完\ntest['Embarked'] = test['Embarked'].fillna(test['Embarked'].mode()[0])\n\n# Fare の欠損を中央値で補完\ntest['Fare'] = test['Fare'].fillna(test['Fare'].median())\n\n# Cabin → 欠損が多すぎるので「有無フラグ」を作成\ntest['Cabin_flag'] = test['Cabin'].notnull().astype(int) \n\n#特徴量追加\n\n# 家族人数 = 同乗の兄弟/配偶者 (SibSp) + 親/子 (Parch) + 自分1人\ntest['FamilySize'] = test['SibSp'] + test['Parch'] + 1\n\ntest['Age*Class'] = test['Age'] * test['Pclass']\n\ntest['Fare_per_person'] = test['Fare'] / (test['FamilySize'])\n#Titanicデータセットの  は チケット単位の合計運賃 を表しています。\n\ntest['IsAlone'] = (test['FamilySize'] == 1).astype(int)\n#test[\"\"FamilySize\"\"] == 1\n\n#不要列削除\n\ncols_to_drop = ['PassengerId', 'Name', 'Ticket', 'Cabin']  # Cabinはフラグ作成済みなので本体は削除\ntest = test.drop(columns=cols_to_drop)\n\n#カテゴリ変数のエンコーディング\n\nfrom sklearn.preprocessing import LabelEncoder\n\n# Sexを0,1に変換\nle = LabelEncoder()\ntest['Sex'] = le.fit_transform(test['Sex'])\n\n# EmbarkedをOne-Hot\ntest = pd.get_dummies(test, columns=['Embarked'], drop_first=True, dtype=int)\n\n#補完後の検査\n\nprint(\"testデータ件数:\", len(test)) #データの 行数（観測数）\nprint() #改行\n\nprint(\"各列の欠損数(補完後):\")\nprint(test.isnull().sum())\nprint() #改行\n\nprint(test.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T16:42:30.488662Z","iopub.execute_input":"2025-10-06T16:42:30.489267Z","iopub.status.idle":"2025-10-06T16:42:30.512145Z","shell.execute_reply.started":"2025-10-06T16:42:30.489243Z","shell.execute_reply":"2025-10-06T16:42:30.511300Z"}},"outputs":[{"name":"stdout","text":"testデータ件数: 418\n\n各列の欠損数(補完後):\nPclass             0\nSex                0\nAge                0\nSibSp              0\nParch              0\nFare               0\nTitle_Miss         0\nTitle_Mr           0\nTitle_Mrs          0\nTitle_Rare         0\nCabin_flag         0\nFamilySize         0\nAge*Class          0\nFare_per_person    0\nIsAlone            0\nEmbarked_Q         0\nEmbarked_S         0\ndtype: int64\n\n   Pclass  Sex   Age  SibSp  Parch     Fare  Title_Miss  Title_Mr  Title_Mrs  \\\n0       3    1  34.5      0      0   7.8292           0         1          0   \n1       3    0  47.0      1      0   7.0000           0         0          1   \n2       2    1  62.0      0      0   9.6875           0         1          0   \n3       3    1  27.0      0      0   8.6625           0         1          0   \n4       3    0  22.0      1      1  12.2875           0         0          1   \n\n   Title_Rare  Cabin_flag  FamilySize  Age*Class  Fare_per_person  IsAlone  \\\n0           0           0           1      103.5         7.829200        1   \n1           0           0           2      141.0         3.500000        0   \n2           0           0           1      124.0         9.687500        1   \n3           0           0           1       81.0         8.662500        1   \n4           0           0           3       66.0         4.095833        0   \n\n   Embarked_Q  Embarked_S  \n0           1           0  \n1           0           1  \n2           1           0  \n3           0           1  \n4           0           1  \n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"#説明変数と目的変数に分ける\n\nX = train.drop(\"Survived\", axis=1)  # 説明変数\ny = train[\"Survived\"]               # 目的変数\n\n#学習データと検証データに分割する\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.3, random_state=42, stratify=y\n)\n\n\n# 形と型の確認\nprint(\"X shape:\", X.shape)\nprint(\"X_train shape:\", X_train.shape, \"X_val shape:\", X_val.shape)\nprint(\"y_train mean (survival rate):\", y_train.mean())\nprint(\"y_val mean (survival rate):\", y_val.mean())\n\n# もし object 型が残っていたら表示\nprint(\"\\nColumn dtypes:\\n\", X.dtypes.value_counts())\nprint(\"\\nObject columns:\", [c for c in X.columns if X[c].dtype == 'object'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T16:43:33.936213Z","iopub.execute_input":"2025-10-06T16:43:33.936503Z","iopub.status.idle":"2025-10-06T16:43:34.055505Z","shell.execute_reply.started":"2025-10-06T16:43:33.936483Z","shell.execute_reply":"2025-10-06T16:43:34.054764Z"}},"outputs":[{"name":"stdout","text":"X shape: (891, 17)\nX_train shape: (623, 17) X_val shape: (268, 17)\ny_train mean (survival rate): 0.38362760834670945\ny_val mean (survival rate): 0.3843283582089552\n\nColumn dtypes:\n int64      13\nfloat64     4\nName: count, dtype: int64\n\nObject columns: []\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"#GridSearchCVでロジスティック回帰\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, roc_auc_score\n\n\n# ハイパーパラメータの候補\nparam_grid = {\n    'C': [0.01, 0.1, 1, 10, 100],   # 正則化の強さ\n    'penalty': ['l1', 'l2'],        # 正則化の種類\n    'solver': ['liblinear']         # solverはliblinearがl1対応\n}\n\n# モデル作成\nlog_reg = LogisticRegression(max_iter=1000)\n\n# GridSearchCVの設定\ngrid_search = GridSearchCV(\n    estimator=log_reg,\n    param_grid=param_grid,\n    scoring='roc_auc',   # ROC-AUCで評価\n    cv=5,                # 5分割交差検証\n    n_jobs=-1            # 並列実行\n)\n\n# 学習\ngrid_search.fit(X_train, y_train)\n\n# ベストなパラメータとスコア\nprint(\"Best Parameters:\", grid_search.best_params_)\nprint(\"Best CV Score:\", grid_search.best_score_)\n\n# バリデーションデータで予測して確認\nbest_model = grid_search.best_estimator_\ny_pred = best_model.predict(X_val)\nprobas = best_model.predict_proba(X_val)[:,1]\n\nprint(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))\nprint(\"Validation ROC AUC:\", roc_auc_score(y_val, probas))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T16:43:39.672163Z","iopub.execute_input":"2025-10-06T16:43:39.672506Z","iopub.status.idle":"2025-10-06T16:43:42.151722Z","shell.execute_reply.started":"2025-10-06T16:43:39.672483Z","shell.execute_reply":"2025-10-06T16:43:42.150807Z"}},"outputs":[{"name":"stdout","text":"Best Parameters: {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\nBest CV Score: 0.8677818291497603\nValidation Accuracy: 0.8208955223880597\nValidation ROC AUC: 0.8692262430126507\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# testデータの前処理（trainと同じ処理を適用しておくこと！）\nX_test = test  # 前処理済み\n\n# 予測\ntest_pred = best_model.predict(X_test)\n\n# 提出用データフレーム\nsubmission = pd.DataFrame({\n    'PassengerId': raw_test['PassengerId'],\n    'Survived': test_pred\n})\n\n# CSV保存\nsubmission.to_csv(\"submission_20251007_title_update.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-06T16:44:50.403177Z","iopub.execute_input":"2025-10-06T16:44:50.403510Z","iopub.status.idle":"2025-10-06T16:44:50.417743Z","shell.execute_reply.started":"2025-10-06T16:44:50.403487Z","shell.execute_reply":"2025-10-06T16:44:50.416812Z"}},"outputs":[],"execution_count":30}]}